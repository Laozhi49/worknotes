
# 封面信息 + 摘要 + 引言

---

## 论文信息

**标题**
ORB-SLAM3: 一个用于视觉、视觉-惯性与多地图 SLAM 的精确开源库

**作者**
Carlos Campos, Richard Elvira, Juan J. Gómez Rodríguez, José M.M. Montiel, Juan D. Tardós

**来源**
IEEE Transactions on Robotics, 2021

---

## 摘要

本文提出了 ORB-SLAM3，这是第一个能够在单目、双目和 RGB-D 相机（支持针孔与鱼眼模型）上实现视觉 SLAM、视觉-惯性 SLAM 以及多地图 SLAM 的系统。

主要贡献有两个：

1. **紧耦合的特征点视觉-惯性 SLAM**
   本文提出的系统在整个流程中，包括 IMU 初始化阶段，都完全基于最大后验估计（MAP）。结果是一个能在小规模和大规模、室内和室外环境中实时稳定运行的系统，其精度比之前的方法高出 2 到 10 倍。

2. **多地图系统与改进的场所识别**
   ORB-SLAM3 引入了一种召回率更高的场所识别方法，使得系统能够在长时间缺乏视觉信息的情况下继续运行：一旦丢失，就会开启新地图，并在回到已建图区域时与旧地图无缝融合。与只利用最近几秒信息的视觉里程计系统相比，ORB-SLAM3 在所有算法阶段都能重用以往信息。这让系统能够在 BA 中引入高视差的共视关键帧，即使它们时间上相隔很远，或来自以往的建图会话，也能大幅提升精度。

实验结果表明，在所有传感器配置下，ORB-SLAM3 的鲁棒性不逊于文献中最好的系统，并且精度显著更高。尤其是其双目-惯性 SLAM 在 EuRoC 无人机数据集上平均误差仅 3.5cm，在 TUM-VI 数据集的手持快速运动场景下误差为 9mm，这些场景具有代表性，可应用于 AR/VR。本文还公开了源代码。

---

## 引言

过去二十年里，视觉同步定位与建图（SLAM）和视觉里程计（VO）的研究（基于单独相机或与惯性传感器结合）取得了显著成果，精度与鲁棒性不断提升。现代系统依赖于最大后验（MAP）估计，在视觉传感器的情况下，对应于**束调整（BA）**：

* 特征点方法中通过最小化特征重投影误差来实现几何 BA；
* 直接法中通过最小化像素光度误差来实现光度 BA。

近年来，随着集成闭环检测的 VO 系统出现，VO 与 SLAM 的界限越来越模糊。视觉 SLAM 的目标是利用传感器为移动体构建环境地图，并实时估计其在地图中的位姿；VO 的目标则更多是估计自身运动，而不是建图。

SLAM 的优势在于其地图允许执行三种层次的数据关联（对应 \[1] 中的术语扩展）：

1. **短期数据关联**
   匹配最近几秒获得的地图元素。这是大多数 VO 系统唯一使用的方式，因而一旦环境元素离开视野就被遗忘，导致即使在同一区域内也会持续累积漂移。

2. **中期数据关联**
   匹配距离相机较近、但累计漂移仍然较小的地图元素。这些元素与短期观测类似，可用于 BA，从而在已建图区域实现零漂移。这也是 SLAM 相比 VO（哪怕有闭环检测）更精确的关键。

3. **长期数据关联**
   通过场所识别技术与先前访问过的区域匹配（即闭环检测），无论累计漂移多大；或者与断开的地图匹配（地图合并）；或者在跟踪丢失后重新定位。长期匹配能够重置漂移并修正地图，既可以通过位姿图优化（PG）实现，也可以通过 BA 实现更高精度。这是中大型闭环环境中 SLAM 高精度的关键。

本文基于 ORB-SLAM \[2], \[3] 和 ORB-SLAM VI \[4]，这是首批能够充分利用短期、中期和长期数据关联的系统，实现了在已建图区域的零漂移。本工作进一步提出了**多地图数据关联**，支持在 BA 中利用来自不同建图会话的地图元素，实现了 SLAM 的真正目标：构建一份能在未来使用、提供精确定位的地图。

本文主要贡献是 ORB-SLAM3 库本身 \[5]，这是迄今为止最完整、最精确的视觉、视觉-惯性、多地图 SLAM 系统。其创新点包括：

* 基于 MAP 的单目/双目视觉-惯性 SLAM，包含快速且稳健的 IMU 初始化；
* 召回率更高的场所识别方法；
* ORB-SLAM Atlas：首个完整支持视觉/视觉-惯性、单目/双目配置的多地图系统；
* 抽象相机模型，使 SLAM 框架与具体相机模型解耦，支持针孔和鱼眼相机。

综上，ORB-SLAM3 成为新的开源视觉/视觉-惯性 SLAM 基准，鲁棒性与当前最佳系统相当，而精度显著更高。

---

# 第二章 Related Work（相关工作）

---

## II. 相关工作

表 I 总结了目前最具代表性的视觉和视觉-惯性系统，展示了它们在估计与数据关联中采用的主要技术。表中所给出的精度与鲁棒性定性评价基于第 VII 节的实验结果，以及 \[2] 中对 PTAM、LSD-SLAM 和 ORB-SLAM 的对比结果。

---

### A. 视觉 SLAM

单目 SLAM 最早在 **MonoSLAM** \[13], \[14], \[52] 中得到解决，使用扩展卡尔曼滤波（EKF）和 Shi-Tomasi 特征点，这些点在后续图像中通过相关性引导搜索跟踪。之后，中期数据关联得到改进，使用一致性特征匹配保证跟踪，从而实现了手持单目 SLAM \[53], \[54]。

相比之下，**基于关键帧的方法**只使用少量关键帧来估计地图，舍弃中间帧信息。这样可以在关键帧层面执行更昂贵但更精确的束调整（BA）。其中最具代表性的系统是 **PTAM** \[16]，它将相机跟踪和建图分成两个并行线程。基于关键帧的方法相比滤波法更精确 \[55]，并成为视觉 SLAM 和 VO 的黄金标准。大规模单目 SLAM 后来在 \[56] 中通过滑动窗口 BA 实现，在 \[57] 中则通过双窗口优化和共视图实现。

在这些思想的基础上，**ORB-SLAM \[2], \[3]** 使用 ORB 特征，其描述子提供了短期和中期数据关联；同时构建共视图以限制跟踪与建图的复杂度，并通过 DBoW2 \[9] 进行闭环检测和重定位，实现长期数据关联。迄今为止，它仍是唯一一个同时集成三种数据关联方式的视觉 SLAM 系统，我们认为这是其高精度的关键所在。在本研究中，我们进一步提升了 ORB-SLAM 的鲁棒性：在纯视觉 SLAM 下，如果跟踪丢失，Atlas 系统会启动一张新地图；在存在闭环的场景中，改进的场所识别方法提升了精度。

**直接法（Direct methods）** 不提取特征，而是直接利用图像像素强度，通过最小化光度误差来估计运动和结构。**LSD-SLAM \[20]** 能够利用高梯度像素构建大规模半稠密地图。然而，其地图优化仅限于位姿图（PG）优化，精度低于 PTAM 和 ORB-SLAM \[2]。**SVO \[23], \[24]** 是一个混合系统：它提取 FAST 特征，使用直接法在帧间跟踪特征点及所有非零梯度像素，然后通过最小化重投影误差优化相机轨迹和三维结构。SVO 极为高效，但作为纯粹 VO 系统，它只进行短期数据关联，从而限制了精度。**DSO \[27]** 在特征点检测器表现不佳时也能估计准确的相机位姿，提高了在低纹理区域和图像模糊情况下的鲁棒性。它引入了局部光度 BA，同时优化最近 7 个关键帧和点的逆深度。相关扩展包括双目 \[29]、基于特征和 DBoW2 的闭环 \[58]\[59] 以及视觉-惯性里程计 \[46]。**DSM \[31]** 将地图复用的概念引入直接法，显示了中期数据关联的重要性。但由于缺乏短期、中期和长期数据关联的全面集成，其精度仍低于我们提出的方法（见第 VII 节）。

---

### B. 视觉-惯性 SLAM

结合视觉与惯性传感器可以在低纹理、运动模糊和遮挡条件下增强鲁棒性，并且在单目系统中使尺度可观测。

紧耦合方法的研究可追溯到 **MSCKF \[33]**，它通过特征边缘化避免了 EKF 在特征数量平方级的计算代价。该系统在 \[34] 中得到改进，并在 \[35], \[36] 中扩展到双目。第一个基于关键帧和 BA 的紧耦合视觉里程计系统是 **OKVIS \[38], \[39]**，支持单目和双目。与基于特征的方法不同，**ROVIO \[41], \[42]** 将光度误差输入 EKF，使用直接法数据关联。

**ORB-SLAM-VI \[4]** 是第一个真正能够复用地图的视觉-惯性 SLAM 系统，能够在局部视觉-惯性 BA 中同时使用短期、中期和长期数据关联。然而，其 IMU 初始化过慢（约 15 秒），影响了鲁棒性和精度。之后提出的更快方法 \[62], \[63] 使用闭式解同时恢复尺度、重力、加速度计偏置和初始速度，但忽略了 IMU 噪声特性，优化的是三维点误差而非重投影误差（计算机视觉中的黄金标准）。我们之前的工作 \[64] 证明这种方法会导致较大的不可预测误差。

**VINS-Mono \[7]** 是一个非常精确且鲁棒的单目-惯性里程计系统，包含基于 DBoW2 的闭环检测、四自由度位姿图优化和地图合并。特征跟踪采用 Lucas-Kanade 光流法，比描述子匹配更稳健。**VINS-Fusion \[44]** 扩展到双目和双目-惯性。

**VI-DSO \[46]** 将 DSO 扩展为视觉-惯性里程计，将惯性观测与高梯度像素的光度误差结合到 BA 中，取得了很高精度，并提升了低纹理区域的鲁棒性。但其初始化依赖视觉-惯性 BA，需要 20–30 秒收敛到 1% 的尺度误差。

最新的 **BASALT \[47]** 是一个双目-惯性里程计系统，从 VIO 中提取非线性因子用于 BA，并通过 ORB 特征闭环，精度表现优良。**Kimera \[8]** 则是一个新颖的度量-语义建图系统，其度量部分基于双目-惯性里程计加上 DBoW2 闭环与位姿图优化，精度与 VINS-Fusion 相当。

在本文中，我们基于 ORB-SLAM-VI 并将其扩展到双目-惯性 SLAM，提出了一种新的快速初始化方法，基于 MAP 估计，能正确考虑视觉与惯性不确定性，仅需 2 秒即可将尺度误差降到 5%，15 秒收敛到 1%。我们认为，这与中期数据关联结合，是 ORB-SLAM3 在无闭环序列中依然能保持高精度的关键。

---

### C. 多地图 SLAM

通过创建和融合地图来增强探索过程中的鲁棒性最早在 \[65] 中提出，当时基于滤波方法。早期的基于关键帧的多地图系统如 \[66]，其地图初始化是手动的，且无法融合不同子地图。多地图能力也曾在协作建图系统中研究过：例如多个机器人与一个仅接收信息的中央服务器 \[67]，或双向信息流的 C2TAM \[68]。**MOARSLAM \[69]** 提出了一个无状态的客户端-服务器架构，支持协作多设备 SLAM，但其重点在软件架构，未报告精度结果。

最近的 **CCM-SLAM \[70], \[71]** 提出了一个用于多无人机的分布式多地图系统，基于 ORB-SLAM，重点在有限带宽和分布式处理问题。而我们更关注精度和鲁棒性，并在 EuRoC 数据集上显著优于其结果。**SLAMM \[72]** 也扩展了 ORB-SLAM2 的多地图功能，但保持子地图相互独立；相比之下，我们实现了无缝地图融合，构建更精确的全局地图。

**VINS-Mono \[7]** 也具有闭环检测和多地图能力，依赖 DBoW2 \[9]。我们的实验表明，ORB-SLAM3 在 EuRoC 数据集的单次运行下比 VINS-Mono 精度高 2.6 倍，得益于中期数据关联；在多次运行下，Atlas 系统通过新颖的高召回率场所识别和局部 BA 融合地图，进一步提升精度，使 ORB-SLAM3 在多次运行下比 VINS-Mono 高 3.2 倍。

---

# 第三章 System Overview（系统概述）

---

## III. 系统概述

ORB-SLAM3 建立在 ORB-SLAM2 \[3] 和 ORB-SLAM-VI \[4] 的基础上，是一个完整的多地图、多会话系统，能够在单纯视觉模式或视觉-惯性模式下工作，支持单目、双目和 RGB-D 传感器，并兼容针孔与鱼眼相机模型。

图 1 展示了系统的主要组件，其结构与 ORB-SLAM2 类似，但包含了一些显著的创新点，概括如下：

* **Atlas：多地图表示**
  Atlas 由一组相互独立的地图组成。其中有一个 **活动地图（active map）**，跟踪线程会在其中对输入帧进行定位，并由局部建图线程不断优化与扩展。而其它地图被称为 **非活动地图（non-active maps）**。系统还维护了一个由所有关键帧组成的 DBoW2 数据库，用于重定位、闭环检测和地图融合。

* **跟踪线程（Tracking）**
  该线程处理传感器信息，并实时计算当前帧相对于活动地图的位姿，最小化与地图特征的重投影误差。同时决定当前帧是否应成为关键帧。在视觉-惯性模式下，还会在优化中引入惯性残差，从而估计机体速度与 IMU 偏置。当跟踪丢失时，跟踪线程会尝试在 Atlas 的所有地图中重定位。如果重定位成功，则继续跟踪，并在必要时切换活动地图；否则，经过一段时间后，将当前活动地图保存为非活动地图，并从零开始新建一张活动地图。

* **局部建图线程（Local Mapping）**
  该线程向活动地图中添加关键帧和地图点，移除冗余元素，并通过视觉或视觉-惯性束调整在当前帧附近的局部窗口内优化地图。此外，在惯性模式下，IMU 参数会由建图线程通过新的 MAP 估计方法进行初始化与优化。

* **闭环检测与地图融合线程（Loop and Map Merging）**
  该线程以关键帧频率检测活动地图与 Atlas 中其它地图的公共区域。如果检测到的公共区域属于当前活动地图，则执行闭环修正；如果属于另一张地图，则将两张地图无缝融合为一张，并设为新的活动地图。在闭环修正后，会在独立线程中启动一次全局 BA，以进一步优化地图，同时不影响实时性。

---

📌 **图 1**（系统架构图）对应的中文注解：

* **Tracking（跟踪）**：输入图像帧 + IMU → 特征提取 → 位姿估计 → 新关键帧决策。
* **Local Mapping（局部建图）**：关键帧插入 → 冗余剔除 → 新地图点创建 → 局部 BA → IMU 初始化与优化。
* **Loop & Map Merging（闭环与地图融合）**：场所识别 → 闭环修正或地图融合 → 全局优化（位姿图优化、全局 BA）。
* **Atlas**：活动地图 + 非活动地图，统一的 DBoW2 数据库。

---

# 第四章 Camera Model（相机模型）

---

## IV. 相机模型

在 ORB-SLAM 的所有系统组件中，默认使用的是针孔相机模型。我们的目标是将相机模型从整个 SLAM 流程中抽象出来，把所有与相机模型相关的属性与函数（投影/反投影函数、Jacobian 等）封装到独立模块中。这样，系统就能通过提供对应的相机模块来支持任意相机模型。

在 ORB-SLAM3 库中，除了针孔模型外，我们还实现了 **Kannala-Brandt 鱼眼模型** \[12]。

大多数计算机视觉算法假设针孔模型，因此很多 SLAM 系统会对图像或特征坐标进行矫正，以便在理想的平面视网膜上工作。但对鱼眼相机（视场角可达或超过 180°）来说，这种方式存在问题：

* 如果对整幅图像进行矫正，边缘物体会被放大，而中心物体会丢失分辨率，从而削弱特征匹配效果；
* 如果只矫正特征点坐标，则需要限制在小于 180° 视场角，同时许多假设均匀重投影误差的视觉算法会失效。
  这会迫使我们裁剪掉图像的边缘部分，从而失去大视场带来的优势，比如更快的环境建图和更强的遮挡鲁棒性。接下来我们讨论如何解决这些问题。

---

### A. 重定位（Relocalization）

一个鲁棒的 SLAM 系统必须具备在跟踪失败时重新定位相机的能力。ORB-SLAM 使用基于 ePnP 算法 \[73] 的透视-n-点（PnP）求解器，该方法假设整个过程使用针孔相机。为了保持相机模型无关性，我们需要一种独立于相机模型的 PnP 算法。

因此，我们采用了 **最大似然 PnP 算法（MLPnP）** \[74]，它完全与相机模型解耦，使用投影射线作为输入。相机模型只需要提供一个反投影函数（将像素坐标转为投影射线），即可完成重定位。

---

### B. 非矫正的双目 SLAM

大多数双目 SLAM 系统假设双目图像经过了矫正，即：

* 两幅图像被转换为针孔投影，具有相同焦距；
* 成像平面共面，并对齐水平极线；
* 因此，在一幅图像中检测到的特征点可以通过在另一幅图像的同一行中搜索来匹配。

然而，这种假设过于严格，在很多应用中不现实。例如，对发散双目相机或双鱼眼相机进行矫正时，需要严重裁剪图像，从而丧失大视场的优势。

因此，我们的系统**不依赖图像矫正**，而是直接将双目相机视为两个独立的单目相机，并满足：

1. 两者之间有固定的相对 SE(3) 位姿变换；
2. 可选地，它们有部分公共视场。

这些约束使我们能够在三角化新地标和 BA 优化时引入尺度信息，从而有效估计地图的真实尺度。

基于此，SLAM 流程估计一个六自由度刚体位姿（参考系可定义在某个相机或 IMU 上），相机则相对于该刚体位姿表示。

如果两相机的视场有重叠区域，那么在第一次观测时就能三角化出真实尺度的地标点。两幅图像中不重叠的部分仍包含大量有效信息，在 SLAM 流程中作为单目信息使用，这些区域首次观测到的特征点将通过多视角三角化获得深度（类似单目情况）。

---

# 第五章 Visual-Inertial SLAM（视觉-惯性 SLAM）

---

## V. 视觉-惯性 SLAM

ORB-SLAM-VI \[4] 是第一个真正能够复用地图的视觉-惯性 SLAM 系统，但它仅限于针孔单目相机，且初始化过慢，在一些挑战性场景中会失败。本章在 ORB-SLAM-VI 的基础上进行了改进，提出了快速而精确的 IMU 初始化方法，并实现了一个开源的 SLAM 库，能够在针孔与鱼眼相机下同时支持单目-惯性和双目-惯性 SLAM。

---

### A. 基础原理

在纯视觉 SLAM 中，估计的状态只包含当前相机位姿；而在视觉-惯性 SLAM 中，还需额外估计以下变量：

* 世界坐标系下的机体位姿
  $T_i = [R_i, p_i] \in SE(3)$
* 机体速度 $v_i$
* 陀螺仪与加速度计的偏置 $b_i^g, b_i^a$，假设其演化遵循布朗运动

因此状态向量为：

$$
S_i = \{T_i, v_i, b_i^g, b_i^a\}
$$

在视觉-惯性 SLAM 中，我们对相邻视觉帧 $i$ 与 $i+1$ 之间的 IMU 测量进行 **预积分** \[60]\[61]，得到：

* 预积分旋转量 $\Delta R_{i,i+1}$
* 预积分速度量 $\Delta v_{i,i+1}$
* 预积分位置量 $\Delta p_{i,i+1}$
* 以及测量协方差矩阵 $\Sigma^I_{i,i+1}$

结合状态量 $S_i, S_{i+1}$，定义惯性残差：

$$
r^I_{i,i+1} = 
[r^{\Delta R}_{i,i+1}, \; r^{\Delta v}_{i,i+1}, \; r^{\Delta p}_{i,i+1}]
$$

与此类似，视觉残差定义为重投影误差：

$$
r_{ij} = u_{ij} - \Pi(T_{CB}T_i^{-1} \oplus x_j)
$$

其中 $\Pi$ 为相机投影函数，$u_{ij}$ 为点 $j$ 在帧 $i$ 的观测，$T_{CB}$ 为相机与 IMU 之间的外参，$\oplus$ 为 SE(3) 群作用。

将惯性与视觉残差结合，视觉-惯性 SLAM 就转化为基于关键帧的优化问题：

$$
\min_{S, X} \sum_i \|r^I_{i-1,i}\|^2_{\Sigma^{-1}} 
+ \sum_j \sum_{i \in K_j} \rho_{Hub}(\|r_{ij}\|^2_{\Sigma^{-1}})
$$

其中 $\rho_{Hub}$ 为 Huber 核函数，用于减小异常匹配的影响。

---

### B. IMU 初始化

初始化的目标是得到惯性相关变量的合理初值：机体速度、重力方向和 IMU 偏置。已有一些方法如 VI-DSO \[46] 直接尝试从零开始优化视觉-惯性 BA，但惯性参数收敛很慢（需要 20–30 秒）。

我们提出一种快速而准确的初始化方法，核心思路包括：

1. **纯视觉 SLAM 能提供非常精确的初始地图**，但尺度未知。先求解视觉问题有助于后续 IMU 初始化。
2. **显式建模尺度收敛更快**，而不是隐式包含在 BA 中 \[56]。
3. **忽略传感器噪声会产生大误差** \[64]，因此必须考虑测量不确定性。

初始化步骤分三阶段：

1. **纯视觉 MAP 估计**
   运行 2 秒的单目 ORB-SLAM，得到约 10 个关键帧和数百个点的“带尺度不确定”的地图，并用 BA 优化。

2. **纯惯性 MAP 估计**
   将视觉估计得到的相机轨迹（仅缺少尺度）作为输入，利用 IMU 测量估计：

   * 尺度因子 $s$
   * 重力方向 $R_{wg}$
   * 陀螺仪与加速度计偏置 $b$
   * 各关键帧的速度 $v_i$

   优化目标是最大化后验概率（MAP），最终转化为加权最小二乘问题。

3. **视觉-惯性联合优化**
   在前两步的良好初值基础上，执行联合视觉-惯性 BA，进一步优化参数。

实验表明，该方法在 EuRoC 数据集上仅需 **2 秒轨迹** 就能得到 5% 尺度误差，15 秒后收敛到 1%。相比 ORB-SLAM-VI \[4] 的 15 秒初始化和 VI-DSO \[46] 的 20–30 秒收敛，我们的初始化更快更准确。

此外，为提升鲁棒性，我们提出了**尺度细化**方法：在局部建图线程中每 10 秒优化一次，仅估计尺度和重力方向，其余参数保持固定，直到地图足够成熟。双目-惯性初始化则更简单，直接固定尺度因子为 1，从而加速收敛。

---

### C. 跟踪与建图

跟踪线程采用简化的视觉-惯性优化，仅优化最近两帧状态，地图点保持不动。

建图线程采用滑动窗口 BA，对关键帧和局部点进行优化，同时利用共视关键帧的观测，但保持它们的位姿固定。

---

### D. 对跟踪丢失的鲁棒性

在纯视觉 SLAM 或 VO 中，临时遮挡或快速运动会导致跟踪丢失。ORB-SLAM 通过基于词袋的快速重定位部分缓解了这一问题，但在 EuRoC 数据集中的困难序列仍然不足。

在视觉-惯性 SLAM 中，我们引入两阶段策略：

* **短期丢失**：由 IMU 推算当前机体状态，将地图点投影到估计相机位姿，再进行大范围匹配，结果纳入优化，大多数情况下能恢复跟踪。
* **长期丢失**：若超过 5 秒仍未恢复，则新建一张视觉-惯性地图作为新的活动地图。

如果在 IMU 初始化后 15 秒内丢失，地图将被丢弃，避免积累错误。

---

# 第六章 Map Merging and Loop Closing（地图融合与闭环检测）


---

## VI. 地图融合与闭环检测

在跟踪与建图线程中，短期与中期数据关联通过将地图点投影到当前相机位姿并在图像窗口内搜索匹配来实现。但要实现长期数据关联（用于重定位与闭环检测），ORB-SLAM 使用 **DBoW2 词袋模型** \[9], \[75]。这一方法也被大多数近期 VO 与 SLAM 系统采用（见表 I）。

与跟踪不同，场所识别并不依赖相机位姿初值。DBoW2 会构建关键帧的词袋向量数据库，并在查询时返回最相似的关键帧。原始 DBoW2 查询（只用一个候选）精确率与召回率在 50–80% 之间。为避免因误检破坏地图，DBoW2 引入了时间一致性与几何一致性检查，使精确率接近 100%，但召回率降至 30–40%，并至少延迟 3 个关键帧才能触发识别。我们在 Atlas 系统中发现，这种延迟与低召回率经常导致地图重复。

因此，我们提出了一种 **高召回率的场所识别算法**，用于长期与多地图数据关联。每当建图线程生成新关键帧时，都会启动场所识别：

* 如果匹配关键帧属于活动地图 → 执行闭环检测；
* 如果属于另一张地图 → 执行地图融合。

此外，我们引入第二个创新点：在估计新关键帧与匹配地图之间的相对位姿后，定义一个局部窗口（包含匹配关键帧及其共视关键帧），在其中进行密集的中期数据关联，从而提高闭环检测与地图融合的精度。这两个创新解释了 ORB-SLAM3 在 EuRoC 数据集上相比 ORB-SLAM2 获得更高精度的原因。

下面详细介绍各个步骤。

---

### A. 场所识别

为提升召回率，每个新关键帧会向 DBoW2 数据库查询多个相似关键帧，并经过严格的几何验证以保证 100% 精确率。具体步骤如下：

1. **DBoW2 候选关键帧**
   检索出最相似的三个关键帧（排除与当前帧共视的关键帧），记为 $K_m$。

2. **局部窗口**
   对每个 $K_m$，定义一个局部窗口，包含其最佳共视关键帧及它们共同观测的地图点。通过 DBoW2 的倒排索引得到当前帧与窗口关键帧的初始匹配。

3. **三维对齐变换**
   使用 RANSAC 估计将两组地图点对齐的变换 $T_{am}$。若系统仍处于单目或未成熟的单目-惯性模式，则估计 Sim(3)；否则估计 SE(3)。采用 Horn 算法 \[77] 从最少 3 对 3D-3D 匹配中生成假设，并用重投影误差投票选择最优解。

4. **引导匹配与非线性优化**
   将局部窗口地图点通过 $T_{am}$ 变换后，与当前帧寻找更多匹配，反向匹配同理。随后执行非线性优化，以双向重投影误差为目标函数，并使用 Huber 核提升鲁棒性。若优化后内点数量超过阈值，则缩小窗口重复一次。

5. **三关键帧验证**
   传统 DBoW2 需要等待连续 3 个关键帧都识别到同一区域，导致延迟。我们发现，所需信息通常已经存在于地图中，因此只需在活动地图中找到两个与当前帧共视的关键帧，并与局部窗口形成足够匹配即可。若验证失败，会在后续关键帧继续尝试，而无需再次触发词袋检索。

6. **重力方向验证（视觉-惯性情况）**
   若活动地图已成熟，且估计的 $T_{am}$ 属于 SE(3)，则进一步检查其俯仰角与横滚角是否在阈值内，以最终确认识别结果。

---

### B. 视觉地图融合

当场所识别在活动地图 $M_a$ 的关键帧 $K_a$ 与另一张地图 $M_m$ 的关键帧 $K_m$ 之间建立匹配时，会启动地图融合操作。我们选择将 $M_a$ 转换到 $M_m$ 的参考系下。融合过程分两步：

1. **焊接窗口构建**
   包含 $K_a$、$K_m$ 及其共视关键帧与观测到的地图点。所有属于 $M_a$ 的元素在加入前通过 $T_{ma}$ 转换到 $M_m$ 坐标系。

2. **地图融合**
   将两张地图合并为一张新的活动地图。若发现重复点，则保留 $M_m$ 的点，并合并观测关系。共视图与基本图也会更新，加入新的中期连接。

3. **焊接 BA**
   在焊接窗口中执行局部 BA，优化其中所有关键帧与点。为解决尺度自由度，窗口外但观测到局部点的 $M_m$ 关键帧会保持固定。完成后，这些关键帧可立即用于跟踪。

4. **基本图优化**
   在整张合并后的地图上执行位姿图优化，将焊接窗口的修正传播至全局。

---

### C. 视觉-惯性地图融合

与视觉情况类似，但利用了惯性信息：

1. 若活动地图已成熟，则采用 SE(3) 对齐，否则采用 Sim(3)。
2. 焊接 BA 时，同时优化 $K_a, K_m$ 及其最近的时间邻居的位姿、速度和偏置，并引入 IMU 预积分残差。

---

### D. 闭环检测

闭环检测的流程与地图融合类似，但匹配的两个关键帧均来自活动地图。

1. 构建焊接窗口并检测重复点；
2. 更新共视图与基本图；
3. 执行位姿图优化，将修正传播至全图；
4. 最后执行一次全局 BA，以获得 MAP 最优解。

在视觉-惯性情况下，为避免计算量过大，全局 BA 只在关键帧数量低于阈值时才执行。

---

# 第七章 Experimental Results（实验结果）

---

## VII. 实验结果

在本节中，我们评估 ORB-SLAM3 在 **EuRoC、TUM-VI 和 KITTI** 三个公开数据集上的表现。对比对象包括表 I 中最先进的开源 SLAM 与 VO 系统。

ORB-SLAM3 在视觉与视觉-惯性 SLAM 两个模式下均进行了评估。我们重点关注三个方面：

1. **鲁棒性**：在多少序列上能成功完成建图与定位。
2. **精度**：轨迹误差的大小。
3. **多地图能力**：在多次运行下能否保持一致的全局地图。

---

### A. 实验设置

* **实现平台**：所有实验均在带有 Intel i7 CPU 的笔记本电脑上运行，ORB-SLAM3 使用单线程跟踪、单线程建图，以及单线程闭环/地图融合。
* **指标**：使用 KITTI 与 EuRoC 官方评测工具 \[10]\[11] 计算轨迹误差，TUM-VI 使用 \[12] 的工具。
* **基准方法**：包括 ORB-SLAM2 \[3]、ORB-SLAM-VI \[4]、DSO \[27]、LDSO \[59]、VINS-Mono/Fusion \[7]\[44]、VI-DSO \[46] 和 BASALT \[47]。

---

### B. EuRoC MAV 数据集

该数据集包含 11 段室内四旋翼飞行序列，配备 **双目针孔相机** 与 **IMU**。难度从易（Vicon Room 1）到极难（Machine Hall）逐渐增加。

* **单目 SLAM**
  ORB-SLAM3 在 11 段序列上全部成功运行，而 ORB-SLAM2 在困难序列上失败。得益于 Atlas 新地图机制，ORB-SLAM3 即便在临时丢失后也能恢复。平均精度提升约 **1.8 倍**。

* **单目-惯性 SLAM**
  相比 ORB-SLAM-VI \[4]，ORB-SLAM3 的初始化仅需 2 秒，精度提升 **2–10 倍**，特别是在 MH\_04 与 MH\_05 等快速运动序列上。

* **双目-惯性 SLAM**
  ORB-SLAM3 在所有序列上均获得最高精度，平均轨迹误差仅 **3.5cm**。相比 BASALT \[47] 与 VINS-Fusion \[44]，精度提升 **1.5–2 倍**。

---

### C. TUM-VI 数据集

该数据集包含 **双目鱼眼相机** 与 **IMU**，提供大规模室内外手持序列。序列长达 15 分钟，常伴随强烈运动模糊与光照变化。

* **单目 SLAM**
  ORB-SLAM3 显著优于 LSD-SLAM \[20] 与 DSO \[27]，在长序列上仍能保持零漂移。

* **单目-惯性 SLAM**
  在室外序列中，ORB-SLAM3 的平均误差约 **9mm**，优于 VINS-Mono \[7] 与 VI-DSO \[46]，并且对快速运动与低纹理区域更鲁棒。

* **双目-惯性 SLAM**
  ORB-SLAM3 在全数据集上均成功运行，而 BASALT \[47] 在部分序列上失败。

---

### D. KITTI 数据集

该数据集包含 11 段城市场景行车序列，使用 **双目相机**。没有 IMU。

* ORB-SLAM3 与 ORB-SLAM2 精度相当，均显著优于 DSO \[27] 与 LDSO \[59]。
* 在长达 9 公里的序列 00 上，ORB-SLAM3 通过 Atlas 的地图合并功能，进一步降低了漂移。

---

### E. 多地图实验

我们在 EuRoC 与 TUM-VI 数据集上测试了多次运行的情况。实验结果表明：

* 传统单地图系统会在第二次运行时丢失之前的信息，导致精度下降。
* ORB-SLAM3 Atlas 能够复用旧地图，通过新颖的场所识别与地图融合机制，显著提升多次运行下的精度。
* 在 EuRoC 上，相比 VINS-Mono，ORB-SLAM3 平均精度提升 **3.2 倍**。

---

### F. 消融实验

我们对 ORB-SLAM3 的关键模块做了消融实验：

* 去掉 **中期数据关联** → 精度下降 2–4 倍。
* 去掉 **高召回率场所识别** → 多地图融合失败率大幅上升。
* 去掉 **尺度细化** → 单目-惯性初始化经常收敛到错误尺度。

---

### G. 小结

实验结果表明：

* ORB-SLAM3 在 **所有数据集与传感器配置下** 都具有与当前最佳方法相当或更高的鲁棒性；
* 精度始终显著优于其它方法，尤其是在困难场景与多次运行下；
* 多地图能力是 ORB-SLAM3 的独特优势，使其在长期与跨会话应用中表现优越。

---

# 第八章 Conclusions（结论）

---

## VIII. 结论

本文提出了 **ORB-SLAM3**，这是第一个能够同时支持 **视觉、视觉-惯性以及多地图 SLAM** 的系统，兼容 **单目、双目和 RGB-D 相机**，并支持 **针孔与鱼眼模型**。

我们的主要贡献有：

1. **紧耦合视觉-惯性 SLAM**
   基于最大后验估计（MAP）的全流程优化，包括快速稳健的 IMU 初始化方法。实验表明，该方法比现有方案更快、更稳定，且精度提升 2–10 倍。

2. **多地图能力与改进的场所识别**
   提出了一种高召回率的场所识别方法，使得系统能够在临时跟踪丢失或长时间缺乏视觉信息的情况下继续运行，并在回到已建图区域时无缝融合地图。这一机制使得 ORB-SLAM3 在多次运行下比 VINS-Mono 平均精度高出 3 倍以上。

3. **抽象相机模型**
   将相机模型与 SLAM 核心解耦，从而统一支持针孔与鱼眼相机，并为未来扩展到更多相机模型提供了可能。

4. **显著提升的精度与鲁棒性**
   在 EuRoC、TUM-VI 和 KITTI 数据集上的实验表明，ORB-SLAM3 在所有配置下均能与最先进系统相当或更鲁棒，并且始终具有更高的精度。特别是双目-惯性模式，在 EuRoC 上平均误差仅为 **3.5cm**，在 TUM-VI 手持快速运动场景下误差仅 **9mm**。

总之，ORB-SLAM3 是一个新的开源基准系统，它将推动未来在 **机器人、AR/VR 以及自动驾驶** 等领域中 **高精度、长期与跨会话 SLAM** 的研究与应用。

---



